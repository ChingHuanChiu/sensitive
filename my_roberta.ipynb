{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 酒店評論數據 : 情感性分析\n",
    "* 數據來源  : https://github.com/SophonPlus/ChineseNlpCorpus/blob/master/datasets/ChnSentiCorp_htl_all/intro.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from train import IMetric, TrainBase\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from processor import DataLoader\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>1</td>\n",
       "      <td>2008.4.5入住该酒店南楼大床间,总体感觉不错，符合三星标准。值得赞一下的是客房送餐很好...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>1</td>\n",
       "      <td>房间还算可以，就是旧了些。早餐没有酸奶，有些美中不足。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>1</td>\n",
       "      <td>很好的酒店，设施和服务都让人满意，就是偏远了一点。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>0</td>\n",
       "      <td>不如新开张时候好了，房间的地毯比较脏，网速是很慢的，电视的操作也非常不人性化。淋浴的地漏下水...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>1</td>\n",
       "      <td>我们是从银滩的酒店住宿后，搬过来的，所以这个酒店虽然离银滩远点，但是也没觉得什么不便，每天去...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>1</td>\n",
       "      <td>周围的环境很好.在房间可以看到大海.普通间很一般.建议住豪华间.价格差不了多少.豪华间非常大...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>0</td>\n",
       "      <td>一句话，那是相当的差！这也叫3星，有没有搞错，旅馆水平都没有。大厅倒过得去。房间里面消毒水的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>1</td>\n",
       "      <td>这里虽然房间不大，但是充满温馨；虽然设施不很豪华，但是比较干净；虽然服务人员不多，但是比较细...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>1</td>\n",
       "      <td>上个周末又去了河源。这回提前预订了万豪国际酒店2个晚上，酒店真的没有令我们夫妇失望，我们为自...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>1</td>\n",
       "      <td>房间的整洁及服务都不错,人员的训练及接待都很亲切,入住的感觉也很不错</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            content\n",
       "1150      1  2008.4.5入住该酒店南楼大床间,总体感觉不错，符合三星标准。值得赞一下的是客房送餐很好...\n",
       "622       1                        房间还算可以，就是旧了些。早餐没有酸奶，有些美中不足。\n",
       "2720      1                          很好的酒店，设施和服务都让人满意，就是偏远了一点。\n",
       "5689      0  不如新开张时候好了，房间的地毯比较脏，网速是很慢的，电视的操作也非常不人性化。淋浴的地漏下水...\n",
       "4758      1  我们是从银滩的酒店住宿后，搬过来的，所以这个酒店虽然离银滩远点，但是也没觉得什么不便，每天去...\n",
       "2312      1  周围的环境很好.在房间可以看到大海.普通间很一般.建议住豪华间.价格差不了多少.豪华间非常大...\n",
       "5402      0  一句话，那是相当的差！这也叫3星，有没有搞错，旅馆水平都没有。大厅倒过得去。房间里面消毒水的...\n",
       "2336      1  这里虽然房间不大，但是充满温馨；虽然设施不很豪华，但是比较干净；虽然服务人员不多，但是比较细...\n",
       "3758      1  上个周末又去了河源。这回提前预订了万豪国际酒店2个晚上，酒店真的没有令我们夫妇失望，我们为自...\n",
       "1868      1                 房间的整洁及服务都不错,人员的训练及接待都很亲切,入住的感觉也很不错"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/sensitive.csv')\n",
    "data = data.rename(columns={'review': 'content'})\n",
    "data = data.dropna(0).reset_index(drop=True)\n",
    "# shuffle the data\n",
    "data = shuffle(data)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7765 entries, 1150 to 2585\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    7765 non-null   int64 \n",
      " 1   content  7765 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 182.0+ KB\n",
      "None\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.info())\n",
    "print('=' * 30)\n",
    "data.content.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * 去除重複標點符號，例如:\"你好!!!!!\" --> \"你好!\"\n",
    "## * 去除跳脫字符與網址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(context):\n",
    "    import re\n",
    "    import numpy\n",
    "    context = context.strip()\n",
    "    context = re.sub(r'[\\s]+|http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F]))', \"\", context)\n",
    "    context = re.sub(r'([?。,!])\\1+', \"\", context)\n",
    "    \n",
    "    return context\n",
    "\n",
    "data['content'] = data['content'].apply(preprocess_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正負樣本比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label\n",
      "1  0.685383\n",
      "0  0.314617\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "value_count = pd.DataFrame(data.label.value_counts(normalize=True))\n",
    "print(value_count)\n",
    "print('=' * 20)\n",
    "value_count.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字數統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'neg'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_len = data[data.label == 1].content.apply(len)\n",
    "neg_len = data[data.label == 0].content.apply(len)\n",
    "pos_len.name, neg_len.name = 'pos_content', 'neg_content'\n",
    "fig, axs = plt.subplots(2, figsize=(8,8))\n",
    "\n",
    "pos_len.plot.hist(ax=axs[0], title='pos',bins=200)\n",
    "neg_len.plot.hist(ax=axs[1], title='neg', bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_content</th>\n",
       "      <th>neg_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5322.000000</td>\n",
       "      <td>2443.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>111.867531</td>\n",
       "      <td>163.998363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>119.109333</td>\n",
       "      <td>180.723843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>135.750000</td>\n",
       "      <td>201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1459.000000</td>\n",
       "      <td>2924.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pos_content  neg_content\n",
       "count  5322.000000  2443.000000\n",
       "mean    111.867531   163.998363\n",
       "std     119.109333   180.723843\n",
       "min       2.000000     2.000000\n",
       "25%      42.000000    57.000000\n",
       "50%      75.000000   108.000000\n",
       "75%     135.750000   201.000000\n",
       "max    1459.000000  2924.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pos_len.describe(), neg_len.describe()], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正向文字小於200字的比例 :  0.8703494926719278\n",
      "負向文字小於200字的比例 :  0.7490790012279983\n"
     ]
    }
   ],
   "source": [
    "count = 200\n",
    "print(f'正向文字小於{count}字的比例 : ',  len(pos_len[pos_len <= count]) / len(pos_len))\n",
    "print(f'負向文字小於{count}字的比例 : ',  len(neg_len[neg_len <= count]) / len(neg_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_point = int(len(data) * 0.8)\n",
    "train_data = data.iloc[:split_point]\n",
    "test_data = data.iloc[split_point:]\n",
    "train_data.to_pickle('./data/train_data/train.pickle')\n",
    "test_data.to_pickle('./data/test_data/test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>1</td>\n",
       "      <td>2008.4.5入住该酒店南楼大床间,总体感觉不错，符合三星标准。值得赞一下的是客房送餐很好...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>1</td>\n",
       "      <td>房间还算可以，就是旧了些。早餐没有酸奶，有些美中不足。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>1</td>\n",
       "      <td>很好的酒店，设施和服务都让人满意，就是偏远了一点。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689</th>\n",
       "      <td>0</td>\n",
       "      <td>不如新开张时候好了，房间的地毯比较脏，网速是很慢的，电视的操作也非常不人性化。淋浴的地漏下水...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>1</td>\n",
       "      <td>我们是从银滩的酒店住宿后，搬过来的，所以这个酒店虽然离银滩远点，但是也没觉得什么不便，每天去...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5029</th>\n",
       "      <td>1</td>\n",
       "      <td>位置好是没得说的，酒店比较老旧了，宽带有的还要收费。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5779</th>\n",
       "      <td>0</td>\n",
       "      <td>千万不要住！首先是走廊和房间都一股发霉的味道！而且早餐超级难吃！最受不了的就是招待所级别的服...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2848</th>\n",
       "      <td>1</td>\n",
       "      <td>房间很一般，但服务员态度还不错。不过听说韶山还有比这个更好的酒店，但携程没有。免费注册网站导...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3767</th>\n",
       "      <td>1</td>\n",
       "      <td>免费自助早餐在该酒店斜对面的阳光.和酒巴.这个酒巴可是被用来拍过电影的哦.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>0</td>\n",
       "      <td>就在美美百</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6212 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            content\n",
       "1150      1  2008.4.5入住该酒店南楼大床间,总体感觉不错，符合三星标准。值得赞一下的是客房送餐很好...\n",
       "622       1                        房间还算可以，就是旧了些。早餐没有酸奶，有些美中不足。\n",
       "2720      1                          很好的酒店，设施和服务都让人满意，就是偏远了一点。\n",
       "5689      0  不如新开张时候好了，房间的地毯比较脏，网速是很慢的，电视的操作也非常不人性化。淋浴的地漏下水...\n",
       "4758      1  我们是从银滩的酒店住宿后，搬过来的，所以这个酒店虽然离银滩远点，但是也没觉得什么不便，每天去...\n",
       "...     ...                                                ...\n",
       "5029      1                         位置好是没得说的，酒店比较老旧了，宽带有的还要收费。\n",
       "5779      0  千万不要住！首先是走廊和房间都一股发霉的味道！而且早餐超级难吃！最受不了的就是招待所级别的服...\n",
       "2848      1  房间很一般，但服务员态度还不错。不过听说韶山还有比这个更好的酒店，但携程没有。免费注册网站导...\n",
       "3767      1              免费自助早餐在该酒店斜对面的阳光.和酒巴.这个酒巴可是被用来拍过电影的哦.\n",
       "6329      0                                              就在美美百\n",
       "\n",
       "[6212 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Basic Train\n",
    "* 用roberta model 建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import IMetric, TrainBase\n",
    "\n",
    "from roberta.model import RoBertaFineTune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_pickle('./data/train_data/train.pickle')\n",
    "split_spot = int(training_data.shape[0] * 0.8)\n",
    "train = training_data.iloc[: split_spot]\n",
    "validation = training_data.iloc[split_spot: ]\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-roberta-wwm-ext\")\n",
    "train_BTL = DataLoader(data=train,\n",
    "                      MAX_SEQUENCE_LENGTH=200,\n",
    "                      batch_size=10,\n",
    "                      imbalance_sample=False,\n",
    "                      tokenizer=tokenizer)\n",
    "\n",
    "val_BTL = DataLoader(data=validation, \n",
    "                     MAX_SEQUENCE_LENGTH=200,\n",
    "                     batch_size=10, \n",
    "                     imbalance_sample=False,\n",
    "                     tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RoBertaFineTune(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define customized metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(IMetric):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.f1 = tfa.metrics.F1Score(num_classes=2, name='f1_score')\n",
    "        self.acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "        self.AUC = tf.keras.metrics.AUC()\n",
    "        self.recall_neg = tf.keras.metrics.Recall(class_id=0)\n",
    "        \n",
    "\n",
    "    def calculate_metric(self, y_batch, logits):\n",
    "        self.f1(to_categorical(y_batch, 2), logits)\n",
    "        self.AUC(to_categorical(y_batch, 2), logits)\n",
    "        self.acc_metric(to_categorical(y_batch, 2), logits)\n",
    "        self.recall_neg(to_categorical(y_batch, 2), logits)\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def get_result(self):\n",
    "        result = dict()\n",
    "        for name, metric in self.__dict__.items():\n",
    "            result_metric =  metric.result()\n",
    "            \n",
    "            try:\n",
    "                #get the f1 score of label=1 \n",
    "                result[name] = result_metric[1]\n",
    "            except:\n",
    "                \n",
    "                result[name] = result_metric\n",
    "           \n",
    "                \n",
    "\n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularTrain(TrainBase):\n",
    "    def __init__(self, model, metric: Metrics):\n",
    "        self.model = model\n",
    "        self.metric = metric\n",
    "\n",
    "    def train_step(self, X_batch, y_batch, optimizer, loss_recoder):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(X_batch)\n",
    "\n",
    "            loss_value = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)(y_batch, logits)\n",
    "\n",
    "            loss_recoder.append(loss_value.numpy())\n",
    "\n",
    "        grads = tape.gradient(loss_value, self.model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "\n",
    "        return logits, loss_recoder\n",
    "\n",
    "    def setting_optimizer(self, decay_steps):\n",
    "        bert_lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=[200, 600, 1200], \n",
    "                                                                                values=[2e-5, 1.5e-5, 1.5e-5*0.5, 1.5e-5*0.25])\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=bert_lr_schedule)\n",
    "        \n",
    "        \n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2e-05, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 0\n",
      "==========================\n",
      "WARNING: AutoGraph could not transform <bound method RoBertaFineTune.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f4a18f678d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertMainLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertMainLayer object at 0x7f4a19104b50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertEmbeddings._embedding of <transformers.models.bert.modeling_tf_bert.TFBertEmbeddings object at 0x7f4a22097410>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertEncoder.call of <transformers.models.bert.modeling_tf_bert.TFBertEncoder object at 0x7f4a18eefdd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x7f4a18f09bd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertAttention object at 0x7f4a18f09390>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertSelfAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertSelfAttention object at 0x7f4a18f09850>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertPooler.call of <transformers.models.bert.modeling_tf_bert.TFBertPooler object at 0x7f4a18150710>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [02:27<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.28685104499910197\n",
      "Training f1 over epoch : 0.9099469780921936\n",
      "Training acc_metric over epoch : 0.876836359500885\n",
      "Training AUC over epoch : 0.9496009945869446\n",
      "Training recall_neg over epoch : 0.7976040244102478\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.42799498462677\n",
      "Validation f1 over epoch : 0.9335548281669617\n",
      "Validation acc_metric over epoch : 0.903459370136261\n",
      "Validation AUC over epoch : 0.966552197933197\n",
      "Validation recall_neg over epoch : 0.7486631274223328\n",
      "============================================================\n",
      "tf.Tensor(1.5e-05, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 1\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [02:20<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.1246123099170243\n",
      "Training f1 over epoch : 0.9656499624252319\n",
      "Training acc_metric over epoch : 0.9533105492591858\n",
      "Training AUC over epoch : 0.9902324080467224\n",
      "Training recall_neg over epoch : 0.9306431412696838\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.4087435846328735\n",
      "Validation f1 over epoch : 0.9299362897872925\n",
      "Validation acc_metric over epoch : 0.9026548862457275\n",
      "Validation AUC over epoch : 0.9621875882148743\n",
      "Validation recall_neg over epoch : 0.8529411554336548\n",
      "============================================================\n",
      "tf.Tensor(7.5e-06, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 2\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [02:21<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.050926236096597174\n",
      "Training f1 over epoch : 0.9887408018112183\n",
      "Training acc_metric over epoch : 0.9847051501274109\n",
      "Training AUC over epoch : 0.998123049736023\n",
      "Training recall_neg over epoch : 0.9810844659805298\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.40875198888778685\n",
      "Validation f1 over epoch : 0.9326655268669128\n",
      "Validation acc_metric over epoch : 0.9026548862457275\n",
      "Validation AUC over epoch : 0.9495038986206055\n",
      "Validation recall_neg over epoch : 0.759358286857605\n",
      "============================================================\n",
      "tf.Tensor(3.75e-06, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 3\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [02:21<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.014082147898171209\n",
      "Training f1 over epoch : 0.9977807402610779\n",
      "Training acc_metric over epoch : 0.9969812631607056\n",
      "Training AUC over epoch : 0.9996352791786194\n",
      "Training recall_neg over epoch : 0.9974779486656189\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.4119042065143585\n",
      "Validation f1 over epoch : 0.927823007106781\n",
      "Validation acc_metric over epoch : 0.9002413749694824\n",
      "Validation AUC over epoch : 0.9508109092712402\n",
      "Validation recall_neg over epoch : 0.8609625697135925\n",
      "============================================================\n",
      "tf.Tensor(3.75e-06, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 4\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [02:21<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.00686092549843397\n",
      "Training f1 over epoch : 0.9989650249481201\n",
      "Training acc_metric over epoch : 0.9985912442207336\n",
      "Training AUC over epoch : 0.9997433423995972\n",
      "Training recall_neg over epoch : 0.9987389445304871\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.4091466705799103\n",
      "Validation f1 over epoch : 0.9307384490966797\n",
      "Validation acc_metric over epoch : 0.9026548862457275\n",
      "Validation AUC over epoch : 0.9454852342605591\n",
      "Validation recall_neg over epoch : 0.8262032270431519\n",
      "============================================================\n",
      "tf.Tensor(3.75e-06, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 5\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [02:21<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.0030090797013867603\n",
      "Training f1 over epoch : 0.9995565414428711\n",
      "Training acc_metric over epoch : 0.9993962645530701\n",
      "Training AUC over epoch : 0.9999926686286926\n",
      "Training recall_neg over epoch : 0.9993695020675659\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.4113434855937958\n",
      "Validation f1 over epoch : 0.9283667802810669\n",
      "Validation acc_metric over epoch : 0.8994368314743042\n",
      "Validation AUC over epoch : 0.9379585981369019\n",
      "Validation recall_neg over epoch : 0.8235294222831726\n",
      "============================================================\n",
      "tf.Tensor(3.75e-06, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 6\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [02:21<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.0010386931244137517\n",
      "Training f1 over epoch : 0.9998522400856018\n",
      "Training acc_metric over epoch : 0.9997987747192383\n",
      "Training AUC over epoch : 0.9999999403953552\n",
      "Training recall_neg over epoch : 1.0\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.4110321269035339\n",
      "Validation f1 over epoch : 0.9307384490966797\n",
      "Validation acc_metric over epoch : 0.9026548862457275\n",
      "Validation AUC over epoch : 0.9318493008613586\n",
      "Validation recall_neg over epoch : 0.8262032270431519\n",
      "============================================================\n",
      "tf.Tensor(3.75e-06, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 7\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [02:25<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.0003135131503638279\n",
      "Training f1 over epoch : 1.0\n",
      "Training acc_metric over epoch : 1.0\n",
      "Training AUC over epoch : 1.0\n",
      "Training recall_neg over epoch : 1.0\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.41134078073501584\n",
      "Validation f1 over epoch : 0.9307384490966797\n",
      "Validation acc_metric over epoch : 0.9026548862457275\n",
      "Validation AUC over epoch : 0.9256030321121216\n",
      "Validation recall_neg over epoch : 0.8262032270431519\n",
      "============================================================\n",
      "tf.Tensor(3.75e-06, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 8\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [02:25<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.00019250114405210556\n",
      "Training f1 over epoch : 1.0\n",
      "Training acc_metric over epoch : 1.0\n",
      "Training AUC over epoch : 0.9999999403953552\n",
      "Training recall_neg over epoch : 1.0\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.41167004251480105\n",
      "Validation f1 over epoch : 0.9295936226844788\n",
      "Validation acc_metric over epoch : 0.9010458588600159\n",
      "Validation AUC over epoch : 0.9239202737808228\n",
      "Validation recall_neg over epoch : 0.8235294222831726\n",
      "============================================================\n",
      "tf.Tensor(3.75e-06, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 9\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [02:27<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.00012974987546170798\n",
      "Training f1 over epoch : 1.0\n",
      "Training acc_metric over epoch : 1.0\n",
      "Training AUC over epoch : 1.0\n",
      "Training recall_neg over epoch : 1.0\n",
      "============================================================\n",
      " loss of validation is 0.41203864884376523\n",
      "Validation f1 over epoch : 0.9295936226844788\n",
      "Validation acc_metric over epoch : 0.9010458588600159\n",
      "Validation AUC over epoch : 0.9228205680847168\n",
      "Validation recall_neg over epoch : 0.8235294222831726\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "RegularTrain(model=model, metric=Metrics).start_to_train(train_data_loader=train_BTL, \n",
    "                                                         epochs=10,\n",
    "                                                         checkpoint_path='./roberta/roberta_checkpoint_v3',\n",
    "                                                         tensorboard_path={'train':f'./roberta/tensorboard/train_roberta_v3', 'validation': f'./roberta/tensorboard/val_roberta_v3'},\n",
    "                                                         validation_data_loader=val_BTL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google papper Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data agument --> back translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_pickle('./data/train_data/train.pickle')\n",
    "split_spot = int(training_data.shape[0] * 0.8)\n",
    "train = training_data.iloc[: split_spot]\n",
    "validation = training_data.iloc[split_spot: ]\n",
    "\n",
    "back_translate_data = pd.read_pickle('./data/augment_data/back_translate_data.pkl').iloc[: split_spot]\n",
    "back_translate_data_train = pd.DataFrame(back_translate_data['back_translate']).rename(columns={'back_translate':'content'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>back_translate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008.4.5入住该酒店南楼大床间,总体感觉不错，符合三星标准。值得赞一下的是客房送餐很好...</td>\n",
       "      <td>2008.4.5从南汇大号床房间开始，整体感觉很好，符合三星标准。房间很好，食物很好，价格不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>房间还算可以，就是旧了些。早餐没有酸奶，有些美中不足。</td>\n",
       "      <td>房间仍然可以，它很老。早餐没有酸奶，美丽有一点。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>很好的酒店，设施和服务都让人满意，就是偏远了一点。</td>\n",
       "      <td>非常好的酒店，设施和服务很满意，它很远。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>不如新开张时候好了，房间的地毯比较脏，网速是很慢的，电视的操作也非常不人性化。淋浴的地漏下水...</td>\n",
       "      <td>有一个新的开口更好，房间的地毯更脏，速度很慢，电视的运作非常稳定。淋浴的地板流失很慢，你将不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>我们是从银滩的酒店住宿后，搬过来的，所以这个酒店虽然离银滩远点，但是也没觉得什么不便，每天去...</td>\n",
       "      <td>在宾坦的酒店住宿后，我们搬家了，所以这家酒店虽然这家酒店离Yintan很远，但它并不是任何不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4964</th>\n",
       "      <td>两个月里面已经住了三次了,当然好啦,交通也很方便哈</td>\n",
       "      <td>它已经在两个月内生活了三次。当然，交通也很方便。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4965</th>\n",
       "      <td>物有所值,但其预定车票的服务太一般,我给他们商务中心要求订次日到西安的卧铺票,除要收我30元...</td>\n",
       "      <td>有钱，但预订机票的服务太一般，我会问他们的商业中心订购睡眠机票到西安，除了收集我30元的门票...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4966</th>\n",
       "      <td>入住的酒店设施有点老，电视机也不较小，跟500元的房价还是有点差距的，不过服务不错，当天还送...</td>\n",
       "      <td>酒店的设施有点老，电视不小，价格500元仍然有点差距，但服务很好，生日鲜花和水果已被发送。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4967</th>\n",
       "      <td>房间小得不像话，早餐差得不像话，绝对不会再光顾。隔壁的南国大酒店看上去不错。晚上想在酒店的餐...</td>\n",
       "      <td>房间不喜欢，早餐是不可移开的，它永远不会再次光顾。南中国宾馆隔壁看起来很好。我想在酒店的餐厅...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4968</th>\n",
       "      <td>“十一”开车去的。在宾馆接线员的热情引领下，较容易地找到了它。然而，进入房间后，一切都变了：...</td>\n",
       "      <td>“11”开车。在酒店运营商的热情下，最容易找到它。但是，在进入房间后，一切都发生了变化：房间...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4969 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  \\\n",
       "0     2008.4.5入住该酒店南楼大床间,总体感觉不错，符合三星标准。值得赞一下的是客房送餐很好...   \n",
       "1                           房间还算可以，就是旧了些。早餐没有酸奶，有些美中不足。   \n",
       "2                             很好的酒店，设施和服务都让人满意，就是偏远了一点。   \n",
       "3     不如新开张时候好了，房间的地毯比较脏，网速是很慢的，电视的操作也非常不人性化。淋浴的地漏下水...   \n",
       "4     我们是从银滩的酒店住宿后，搬过来的，所以这个酒店虽然离银滩远点，但是也没觉得什么不便，每天去...   \n",
       "...                                                 ...   \n",
       "4964                          两个月里面已经住了三次了,当然好啦,交通也很方便哈   \n",
       "4965  物有所值,但其预定车票的服务太一般,我给他们商务中心要求订次日到西安的卧铺票,除要收我30元...   \n",
       "4966  入住的酒店设施有点老，电视机也不较小，跟500元的房价还是有点差距的，不过服务不错，当天还送...   \n",
       "4967  房间小得不像话，早餐差得不像话，绝对不会再光顾。隔壁的南国大酒店看上去不错。晚上想在酒店的餐...   \n",
       "4968  “十一”开车去的。在宾馆接线员的热情引领下，较容易地找到了它。然而，进入房间后，一切都变了：...   \n",
       "\n",
       "                                         back_translate  \n",
       "0     2008.4.5从南汇大号床房间开始，整体感觉很好，符合三星标准。房间很好，食物很好，价格不...  \n",
       "1                              房间仍然可以，它很老。早餐没有酸奶，美丽有一点。  \n",
       "2                                  非常好的酒店，设施和服务很满意，它很远。  \n",
       "3     有一个新的开口更好，房间的地毯更脏，速度很慢，电视的运作非常稳定。淋浴的地板流失很慢，你将不...  \n",
       "4     在宾坦的酒店住宿后，我们搬家了，所以这家酒店虽然这家酒店离Yintan很远，但它并不是任何不...  \n",
       "...                                                 ...  \n",
       "4964                           它已经在两个月内生活了三次。当然，交通也很方便。  \n",
       "4965  有钱，但预订机票的服务太一般，我会问他们的商业中心订购睡眠机票到西安，除了收集我30元的门票...  \n",
       "4966      酒店的设施有点老，电视不小，价格500元仍然有点差距，但服务很好，生日鲜花和水果已被发送。  \n",
       "4967  房间不喜欢，早餐是不可移开的，它永远不会再次光顾。南中国宾馆隔壁看起来很好。我想在酒店的餐厅...  \n",
       "4968  “11”开车。在酒店运营商的热情下，最容易找到它。但是，在进入房间后，一切都发生了变化：房间...  \n",
       "\n",
       "[4969 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_translate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-roberta-wwm-ext\")\n",
    "train_BTL = DataLoader(data=train,\n",
    "                      MAX_SEQUENCE_LENGTH=200,\n",
    "                      batch_size=10,\n",
    "                      imbalance_sample=False,\n",
    "                      tokenizer=tokenizer)\n",
    "\n",
    "val_BTL = DataLoader(data=validation, \n",
    "                     MAX_SEQUENCE_LENGTH=200,\n",
    "                     batch_size=10, \n",
    "                     imbalance_sample=False,\n",
    "                     tokenizer=tokenizer)\n",
    "\n",
    "back_translate_BTL = DataLoader(data=back_translate_data_train, \n",
    "                     MAX_SEQUENCE_LENGTH=200,\n",
    "                     batch_size=10, \n",
    "                     imbalance_sample=False,\n",
    "                     tokenizer=tokenizer,\n",
    "                     mode='no label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overriding the 'start_to_train' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "from train import TensorBoard\n",
    "class BackTranslationTrain(TrainBase):\n",
    "    def __init__(self, model, metric: Metrics):\n",
    "        self.model = model\n",
    "        self.metric = metric\n",
    "        self.back_translation_yielder = None\n",
    "        \n",
    "    def train_step(self, X_batch, y_batch, optimizer, loss_recoder):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = self.model(X_batch)\n",
    "            data_batch = next(iter(self.back_translation_yielder))\n",
    "            back_translate_x_batch = data_batch[0:3]\n",
    "#             print( back_translate_x_batch)\n",
    "\n",
    "            crossentropy_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)(y_batch, logits)\n",
    "            kl_loss = self._calculate_KLDivergence_loss_for_back_translation(X_batch_logits=logits, back_translate_x_batch=back_translate_x_batch)\n",
    "            \n",
    "            _lambda = 1 \n",
    "            loss_value = crossentropy_loss + (_lambda * kl_loss)\n",
    "\n",
    "            loss_recoder.append(loss_value.numpy())\n",
    "\n",
    "        grads = tape.gradient(loss_value, self.model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "\n",
    "        return logits, loss_recoder\n",
    "    \n",
    "    def setting_optimizer(self, decay_steps):\n",
    "        bert_lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=[200, 600, 1200], \n",
    "                                                                                values=[2e-5, 1.5e-5, 1.5e-5*0.5, 1.5e-5*0.25])\n",
    "\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=bert_lr_schedule)\n",
    "        return optimizer\n",
    "    \n",
    "    \n",
    "    def start_to_train(self, train_data_loader,\n",
    "                   epochs,\n",
    "                   checkpoint_path,\n",
    "                   tensorboard_path: dict,\n",
    "                   back_translation_data_loader,\n",
    "                   validation_data_loader=None,\n",
    "                   ):\n",
    "\n",
    "        BATCH_LENGHT = math.ceil(train_data_loader.data.shape[0] / train_data_loader.batch_size)\n",
    "\n",
    "        # saving manager\n",
    "        checkpoint = tf.train.Checkpoint(Model=self.model)\n",
    "        #         manager = tf.train.CheckpointManager(checkpoint, directory=checkpoint_path, max_to_keep=10)\n",
    "\n",
    "        # Initialize Metric\n",
    "        TrainMetric = self.metric()\n",
    "\n",
    "        writer = tf.summary.create_file_writer(tensorboard_path['train'])\n",
    "\n",
    "        optimizer = self.setting_optimizer(decay_steps=epochs)\n",
    "        for epoch in range(epochs):\n",
    "            print(optimizer.lr(optimizer.iterations))\n",
    "            print('==========================')\n",
    "            print(f'EPOCH {epoch}')\n",
    "            print('==========================')\n",
    "\n",
    "            loss_recoder = []\n",
    "\n",
    "            #             tf.summary.trace_on(graph=True)\n",
    "            self.back_translation_yielder = self._yield_back_translation_btl(back_translation_data_loader)\n",
    "            for step, (X_batch_train, y_batch_train) in tqdm(enumerate(train_data_loader), total=BATCH_LENGHT):\n",
    "                logits, loss_recoder = self.train_step(X_batch=X_batch_train,\n",
    "                                                       y_batch=y_batch_train,\n",
    "                                                       optimizer=optimizer,\n",
    "                                                       loss_recoder=loss_recoder)\n",
    "\n",
    "                TrainMetric.calculate_metric(y_batch_train, logits=logits)\n",
    "                if step % 500 == 0:\n",
    "                    #                     manager.save(checkpoint_number=step)\n",
    "                    checkpoint.save(f'{checkpoint_path}/ckpt-epoch:{epoch}')\n",
    "\n",
    "            epoch_loss = sum(loss_recoder) / len(loss_recoder)\n",
    "\n",
    "            print(f\"training loss is {epoch_loss}\")\n",
    "\n",
    "            for name, result in TrainMetric.get_result.items():\n",
    "                print(f'Training {name} over epoch : {float(result)}')\n",
    "            print('============================================================')\n",
    "\n",
    "            #             with writer.as_default():\n",
    "            #                 tf.summary.trace_export(name=\"my_trace\",step=0)\n",
    "\n",
    "            TrainTB = TensorBoard(writer=writer,\n",
    "                                  model=self.model)\n",
    "            TrainTB.start_to_write(metrics_result=TrainMetric.get_result,\n",
    "                                   step=epoch,\n",
    "                                   loss=epoch_loss,\n",
    "                                   histogram=True,\n",
    "                                   optimizer=optimizer)\n",
    "\n",
    "            TrainMetric.reset()\n",
    "\n",
    "            if validation_data_loader is not None:\n",
    "                self._validation(validation_data_loader=validation_data_loader,\n",
    "                                 val_logdir=tensorboard_path['validation'],\n",
    "                                 ep=epoch)\n",
    "\n",
    "    \n",
    "    \n",
    "    def _yield_back_translation_btl(self, back_translation_data: DataLoader): \n",
    "        yield from back_translation_data\n",
    "        \n",
    "    def _calculate_KLDivergence_loss_for_back_translation(self, X_batch_logits, back_translate_x_batch):\n",
    "        back_translate_x_logits = self.model(back_translate_x_batch)\n",
    "        kl_loss = tf.keras.losses.KLDivergence()(X_batch_logits, back_translate_x_logits)\n",
    "        return kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RoBertaFineTune(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2e-05, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 0\n",
      "==========================\n",
      "WARNING: AutoGraph could not transform <bound method RoBertaFineTune.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fedec87c650>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertMainLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertMainLayer object at 0x7feded420650>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertEmbeddings._embedding of <transformers.models.bert.modeling_tf_bert.TFBertEmbeddings object at 0x7fedf9a138d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertEncoder.call of <transformers.models.bert.modeling_tf_bert.TFBertEncoder object at 0x7feded284490>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x7fedec7a0290>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertAttention object at 0x7fedec7a00d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertSelfAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertSelfAttention object at 0x7fedf7cc3550>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertPooler.call of <transformers.models.bert.modeling_tf_bert.TFBertPooler object at 0x7feded284990>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [04:24<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.31330701283046175\n",
      "Training f1 over epoch : 0.9137780666351318\n",
      "Training acc_metric over epoch : 0.8808613419532776\n",
      "Training AUC over epoch : 0.9550256729125977\n",
      "Training recall_neg over epoch : 0.7818410992622375\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.43640807914733887\n",
      "Validation f1 over epoch : 0.9238302111625671\n",
      "Validation acc_metric over epoch : 0.8873692750930786\n",
      "Validation AUC over epoch : 0.9634450674057007\n",
      "Validation recall_neg over epoch : 0.6791443824768066\n",
      "============================================================\n",
      "tf.Tensor(1.5e-05, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 1\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [04:17<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.1713484374082964\n",
      "Training f1 over epoch : 0.9645599126815796\n",
      "Training acc_metric over epoch : 0.9517005681991577\n",
      "Training AUC over epoch : 0.9899201989173889\n",
      "Training recall_neg over epoch : 0.9224464297294617\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.4041449258327484\n",
      "Validation f1 over epoch : 0.9381443858146667\n",
      "Validation acc_metric over epoch : 0.9131134152412415\n",
      "Validation AUC over epoch : 0.9727451801300049\n",
      "Validation recall_neg over epoch : 0.8449198007583618\n",
      "============================================================\n",
      "tf.Tensor(7.5e-06, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 2\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [04:17<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.09792406513248861\n",
      "Training f1 over epoch : 0.9834221005439758\n",
      "Training acc_metric over epoch : 0.9774602651596069\n",
      "Training AUC over epoch : 0.9974770545959473\n",
      "Training recall_neg over epoch : 0.9678436517715454\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.39937058281898496\n",
      "Validation f1 over epoch : 0.9399656653404236\n",
      "Validation acc_metric over epoch : 0.9155269265174866\n",
      "Validation AUC over epoch : 0.9711090326309204\n",
      "Validation recall_neg over epoch : 0.8449198007583618\n",
      "============================================================\n",
      "tf.Tensor(3.75e-06, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 3\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [04:20<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.05729922820215246\n",
      "Training f1 over epoch : 0.9920213222503662\n",
      "Training acc_metric over epoch : 0.9891326427459717\n",
      "Training AUC over epoch : 0.9991122484207153\n",
      "Training recall_neg over epoch : 0.9823455214500427\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.39723227167129516\n",
      "Validation f1 over epoch : 0.9362688660621643\n",
      "Validation acc_metric over epoch : 0.9115044474601746\n",
      "Validation AUC over epoch : 0.9671357870101929\n",
      "Validation recall_neg over epoch : 0.8689839839935303\n",
      "============================================================\n",
      "tf.Tensor(3.75e-06, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 4\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [04:20<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.03545338292423471\n",
      "Training f1 over epoch : 0.9955608248710632\n",
      "Training acc_metric over epoch : 0.9939625859260559\n",
      "Training AUC over epoch : 0.9993152618408203\n",
      "Training recall_neg over epoch : 0.993064284324646\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.4000521020889282\n",
      "Validation f1 over epoch : 0.936896026134491\n",
      "Validation acc_metric over epoch : 0.9106999039649963\n",
      "Validation AUC over epoch : 0.9603378176689148\n",
      "Validation recall_neg over epoch : 0.8235294222831726\n",
      "============================================================\n",
      "tf.Tensor(3.75e-06, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 5\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [04:21<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.02684514303127176\n",
      "Training f1 over epoch : 0.997633159160614\n",
      "Training acc_metric over epoch : 0.9967800378799438\n",
      "Training AUC over epoch : 0.999362587928772\n",
      "Training recall_neg over epoch : 0.99684739112854\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.4044620838165283\n",
      "Validation f1 over epoch : 0.9329608678817749\n",
      "Validation acc_metric over epoch : 0.903459370136261\n",
      "Validation AUC over epoch : 0.9522846341133118\n",
      "Validation recall_neg over epoch : 0.7700534462928772\n",
      "============================================================\n",
      "tf.Tensor(3.75e-06, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 6\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [04:21<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.015559593322045043\n",
      "Training f1 over epoch : 0.9983725547790527\n",
      "Training acc_metric over epoch : 0.997786283493042\n",
      "Training AUC over epoch : 0.9994890689849854\n",
      "Training recall_neg over epoch : 0.9987389445304871\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.39713256096839905\n",
      "Validation f1 over epoch : 0.9396502375602722\n",
      "Validation acc_metric over epoch : 0.9139179587364197\n",
      "Validation AUC over epoch : 0.9523666501045227\n",
      "Validation recall_neg over epoch : 0.8101603984832764\n",
      "============================================================\n",
      "tf.Tensor(3.75e-06, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 7\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [04:21<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.01704380734049728\n",
      "Training f1 over epoch : 0.9982243180274963\n",
      "Training acc_metric over epoch : 0.9975849986076355\n",
      "Training AUC over epoch : 0.9993069171905518\n",
      "Training recall_neg over epoch : 0.9987389445304871\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.4024661900997162\n",
      "Validation f1 over epoch : 0.9330199360847473\n",
      "Validation acc_metric over epoch : 0.9082863926887512\n",
      "Validation AUC over epoch : 0.9539939761161804\n",
      "Validation recall_neg over epoch : 0.8957219123840332\n",
      "============================================================\n",
      "tf.Tensor(3.75e-06, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 8\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [04:23<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.01763424325224445\n",
      "Training f1 over epoch : 0.9983730316162109\n",
      "Training acc_metric over epoch : 0.997786283493042\n",
      "Training AUC over epoch : 0.9994682669639587\n",
      "Training recall_neg over epoch : 0.998108446598053\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loss of validation is 0.3976629776954651\n",
      "Validation f1 over epoch : 0.939150333404541\n",
      "Validation acc_metric over epoch : 0.9147224426269531\n",
      "Validation AUC over epoch : 0.9572155475616455\n",
      "Validation recall_neg over epoch : 0.8529411554336548\n",
      "============================================================\n",
      "tf.Tensor(3.75e-06, shape=(), dtype=float32)\n",
      "==========================\n",
      "EPOCH 9\n",
      "==========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497/497 [04:23<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss is 0.010047289896257488\n",
      "Training f1 over epoch : 0.9989650249481201\n",
      "Training acc_metric over epoch : 0.9985912442207336\n",
      "Training AUC over epoch : 0.9997690916061401\n",
      "Training recall_neg over epoch : 0.9987389445304871\n",
      "============================================================\n",
      " loss of validation is 0.3977262268066406\n",
      "Validation f1 over epoch : 0.93746417760849\n",
      "Validation acc_metric over epoch : 0.912308931350708\n",
      "Validation AUC over epoch : 0.952040433883667\n",
      "Validation recall_neg over epoch : 0.8475936055183411\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "BackTranslationTrain(model=model, metric=Metrics).start_to_train(train_data_loader=train_BTL, \n",
    "                                                                 epochs=10,\n",
    "                                                                 checkpoint_path='./roberta/back_translate_roberta_checkpoint_v3',\n",
    "                                                                 tensorboard_path={'train':f'./roberta/tensorboard/back_translate_train_roberta_v3', 'validation': f'./roberta/tensorboard/back_translate_val_roberta_v3'},\n",
    "                                                                 validation_data_loader=val_BTL, \n",
    "                                                                 back_translation_data_loader=back_translate_BTL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-roberta-wwm-ext\")\n",
    "\n",
    "test = pd.read_pickle('./data/test_data/test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcuate_test_loss(y_pred_logitis, y_true):\n",
    "#     y_true = [y_true.map({'negative':1, 'positive':0}).iloc[0]]\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)(y_true, y_pred_logitis)\n",
    "    return loss\n",
    "\n",
    "def predict(model, test_data):\n",
    "    y_pred_li, y_pred_logitis_li, pooler_out_li = [], [], []\n",
    "    predict_loss = []\n",
    "    for i in range(0, len(test_data), 1):\n",
    "        data = test_data.iloc[i : i + 1]\n",
    "\n",
    "        pred_BTL = DataLoader(data=data ,\n",
    "                         MAX_SEQUENCE_LENGTH=200,\n",
    "                         batch_size=len(data), \n",
    "                         imbalance_sample=False,\n",
    "                         tokenizer=tokenizer)\n",
    "\n",
    "        y_pred, y_pred_logitis, pooler_out  = model.predict(pred_BTL, model=model, return_logistis_and_pooler=True)\n",
    "        predict_loss.append(calcuate_test_loss(y_pred_logitis, test_data.iloc[i : i + 1]['label']))\n",
    "        y_pred_li.extend(list(y_pred.numpy()))\n",
    "        y_pred_logitis_li.extend(list(y_pred_logitis.numpy().max(-1)))\n",
    "        pooler_out_li.append(pooler_out.numpy())\n",
    "    return y_pred_li, y_pred_logitis_li, pooler_out_li, predict_loss\n",
    "    \n",
    "from sklearn.metrics import classification_report\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Greens):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....model is loading\n",
      "You got it\n",
      "WARNING: AutoGraph could not transform <bound method RoBertaFineTune.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7ff48021fd90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertMainLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertMainLayer object at 0x7ff4801aac90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertEmbeddings._embedding of <transformers.models.bert.modeling_tf_bert.TFBertEmbeddings object at 0x7ff4801aab10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertEncoder.call of <transformers.models.bert.modeling_tf_bert.TFBertEncoder object at 0x7ff488101b90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x7ff4801a5d50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertAttention object at 0x7ff4801a5c90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertSelfAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertSelfAttention object at 0x7ff4801a5910>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertPooler.call of <transformers.models.bert.modeling_tf_bert.TFBertPooler object at 0x7ff488101bd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "CPU times: user 1min 51s, sys: 1.29 s, total: 1min 52s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "general_roberta = RoBertaFineTune(False).load_model('./roberta/roberta_checkpoint_v3/', latest=True)\n",
    "y_pred_li, y_pred_logitis_li, pooler_out_li, predict_loss = predict(general_roberta, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD4CAYAAAAdIcpQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAT8klEQVR4nO3df7BfdX3n8efLREXslh9yS2kSG9pmcFmrY3pFumy7rKkIYgndbS1MqynLNrtTbLE6o4HtlE67zuCsK8JOy24KqcFSKEW7ZCutRtQ6O1N+BLD8lCWLQG4EcxUEK9Y09b1/fD8pX+MN55vk++Mm9/mY+c49530+33Pe3zHeF+d8zvfcVBWSJL2QF026AUnS/GdYSJI6GRaSpE6GhSSpk2EhSeq0eNINjMIxxxxTy5cvn3QbknRQufPOO79aVVNzbTskw2L58uVs2bJl0m1I0kElyWN72+ZlKElSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUaWVgk2ZBkR5L75tj2niSV5Ji2niRXJNma5J4kK/vGrknycHutGVW/kqS9G+WZxUeA0/csJlkGnAY83lc+A1jRXmuBK9vYo4FLgDcAJwGXJDlqhD1LkuYwsm9wV9XnkyyfY9NlwHuBm/pqq4FrqveXmG5NcmSS44BTgc1V9RRAks30Aui6UfUNsHzdJ0a5+7169NIzJ3JcSeoy1jmLJKuB7VX1t3tsWgJs61ufabW91efa99okW5JsmZ2dHWLXkqSxhUWSw4GLgd8exf6ran1VTVfV9NTUnM/BkiTtp3GeWfwocDzwt0keBZYCdyX5QWA7sKxv7NJW21tdkjRGYwuLqrq3qn6gqpZX1XJ6l5RWVtWTwCbgHe2uqJOBZ6rqCeCTwGlJjmoT26e1miRpjEZ56+x1wN8AJySZSXL+Cwy/GXgE2Ar8IfBrAG1i+/eAO9rrd3dPdkuSxmeUd0Od27F9ed9yARfsZdwGYMNQm5Mk7RO/wS1J6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqdPIwiLJhiQ7ktzXV/uvSb6Y5J4kf57kyL5tFyXZmuShJG/uq5/ealuTrBtVv5KkvRvlmcVHgNP3qG0GXl1VrwH+L3ARQJITgXOAf9He8wdJFiVZBPw+cAZwInBuGytJGqORhUVVfR54ao/ap6pqV1u9FVjallcD11fVt6vqS8BW4KT22lpVj1TVTuD6NlaSNEaTnLP498BftuUlwLa+bTOttrf690iyNsmWJFtmZ2dH0K4kLVwTCYsk/xnYBVw7rH1W1fqqmq6q6ampqWHtVpIELB73AZP8CvBWYFVVVStvB5b1DVvaarxAXZI0JmM9s0hyOvBe4Kyqeq5v0ybgnCQvTXI8sAK4HbgDWJHk+CQvoTcJvmmcPUuSRnhmkeQ64FTgmCQzwCX07n56KbA5CcCtVfWfqur+JDcAD9C7PHVBVf1j2887gU8Ci4ANVXX/qHqWJM1tZGFRVefOUb76Bca/H3j/HPWbgZuH2JokaR/5DW5JUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSp5GFRZINSXYkua+vdnSSzUkebj+PavUkuSLJ1iT3JFnZ9541bfzDSdaMql9J0t6N8sziI8Dpe9TWAbdU1QrglrYOcAawor3WAldCL1yAS4A3ACcBl+wOGEnS+IwsLKrq88BTe5RXAxvb8kbg7L76NdVzK3BkkuOANwObq+qpqnoa2Mz3BpAkacTGPWdxbFU90ZafBI5ty0uAbX3jZlptb/XvkWRtki1JtszOzg63a0la4CY2wV1VBdQQ97e+qqaranpqampYu5UkMf6w+Eq7vET7uaPVtwPL+sYtbbW91SVJYzTusNgE7L6jaQ1wU1/9He2uqJOBZ9rlqk8CpyU5qk1sn9ZqkqQxWjyqHSe5DjgVOCbJDL27mi4FbkhyPvAY8LY2/GbgLcBW4DngPICqeirJ7wF3tHG/W1V7TppLkkZsZGFRVefuZdOqOcYWcMFe9rMB2DDE1iRJ+8hvcEuSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6DRQWSX581I1IkuavQc8s/iDJ7Ul+LckRI+1IkjTvDBQWVfVTwC/Re1z4nUn+JMmbRtqZJGneGHjOoqoeBn4LeB/wr4Erknwxyb8dVXOSpPlh0DmL1yS5DHgQeCPws1X1z9vyZSPsT5I0Dwz6iPL/DlwFXFxV39pdrKovJ/mtkXQmSZo3Bg2LM4FvVdU/AiR5EXBYVT1XVR8dWXeSpHlh0DmLTwMv61s/vNUkSQvAoGFxWFX93e6Vtnz4aFqSJM03g4bFN5Os3L2S5CeAb73AeEnSIWTQOYt3AX+W5MtAgB8EfnFUTUmS5peBwqKq7kjyKuCEVnqoqv5hfw+a5DeB/wAUcC9wHnAccD3wCuBO4O1VtTPJS4FrgJ8Avgb8YlU9ur/HliTtu315kODrgdcAK4Fzk7xjfw6YZAnwG8B0Vb0aWAScA3wAuKyqfgx4Gji/veV84OlWv6yNkySN0aBfyvso8EHgX9ELjdcD0wdw3MXAy5IspjdR/gS9L/jd2LZvBM5uy6vbOm37qiQ5gGNLkvbRoHMW08CJVVUHesCq2p7kg8Dj9CbJP0XvstPXq2pXGzYDLGnLS4Bt7b27kjxD71LVV/v3m2QtsBbgla985YG2KUnqM+hlqPvoTWofsCRH0TtbOB74IeDlwOkHut+qWl9V01U1PTU1daC7kyT1GfTM4hjggSS3A9/eXayqs/bjmD8DfKmqZgGSfBw4BTgyyeJ2drEU2N7Gb6f3tNuZdtnqCHoT3ZKkMRk0LH5niMd8HDg5yeH0LkOtArYAnwV+nt4dUWuAm9r4TW39b9r2zwzjcpgkaXCD3jr710l+GFhRVZ9uv+gX7c8Bq+q2JDcCdwG7gLuB9cAngOuT/JdWu7q95Wrgo0m2Ak/Ru3NKkjRGA4VFkl+lN3l8NPCj9Cad/we9s4J9VlWXAJfsUX4EOGmOsX8P/ML+HEeSNByDTnBfQG9e4Vn4pz+E9AOjakqSNL8MGhbfrqqdu1faRLPzBpK0QAwaFn+d5GJ6X6R7E/BnwP8eXVuSpPlk0LBYB8zSe47TfwRupvf3uCVJC8Cgd0N9B/jD9pIkLTCD3g31JeaYo6iqHxl6R5KkeWdfng2122H0bmU9evjtSJLmo4HmLKrqa32v7VX1YeDM0bYmSZovBr0MtbJv9UX0zjQGPSuRJB3kBv2F/9/6lncBjwJvG3o3kqR5adC7of7NqBuRJM1fg16GevcLba+qDw2nHUnSfLQvd0O9nt7jwgF+FrgdeHgUTUmS5pdBw2IpsLKqvgGQ5HeAT1TVL4+qMUnS/DHo4z6OBXb2re9sNUnSAjDomcU1wO1J/rytnw1sHElHkqR5Z9C7od6f5C+Bn2ql86rq7tG1JUmaTwa9DAVwOPBsVV0OzCQ5fkQ9SZLmmYHCIsklwPuAi1rpxcAfj6opSdL8MuiZxc8BZwHfBKiqLwP/bFRNSZLml0HDYmdVFe0x5UlefiAHTXJkkhuTfDHJg0l+MsnRSTYnebj9PKqNTZIrkmxNcs8ez6mSJI3BoGFxQ5L/CRyZ5FeBT3NgfwjpcuCvqupVwGuBB+n9Nb5bqmoFcEtbBzgDWNFea4ErD+C4kqT90Hk3VJIAfwq8CngWOAH47aravD8HTHIE8NPArwBU1U5gZ5LVwKlt2Ebgc/TmSVYD17Qzm1vbWclxVfXE/hxfkrTvOsOiqirJzVX148B+BcQejqf397z/KMlrgTuBC4Fj+wLgSZ7/0t8SYFvf+2dazbCQpDEZ9DLUXUleP6RjLgZWAldW1evoTZqv6x/QPz8yqCRrk2xJsmV2dnZIrUqSYPCweAO9S0D/r00y35vknv085gwwU1W3tfUb6YXHV5IcB9B+7mjbtwPL+t6/tNW+S1Wtr6rpqpqempraz9YkSXN5wctQSV5ZVY8Dbx7WAavqySTbkpxQVQ8Bq4AH2msNcGn7eVN7yybgnUmupxdazzhfIUnj1TVn8b/oPW32sSQfq6p/N6Tj/jpwbZKXAI8A59E7y7khyfnAYzz/l/huBt4CbAWea2MlSWPUFRbpW/6RYR20qr5A729k7GnVHGMLuGBYx5Yk7buuOYvay7IkaQHpOrN4bZJn6Z1hvKwt09arqr5/pN1JkuaFFwyLqlo0rkYkSfPXvjyiXJK0QBkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkThMLiySLktyd5C/a+vFJbkuyNcmfJnlJq7+0rW9t25dPqmdJWqgmeWZxIfBg3/oHgMuq6seAp4HzW/184OlWv6yNkySN0UTCIslS4EzgqrYe4I3AjW3IRuDstry6rdO2r2rjJUljMqkziw8D7wW+09ZfAXy9qna19RlgSVteAmwDaNufaeO/S5K1SbYk2TI7OzvC1iVp4Rl7WCR5K7Cjqu4c5n6ran1VTVfV9NTU1DB3LUkL3uIJHPMU4KwkbwEOA74fuBw4MsnidvawFNjexm8HlgEzSRYDRwBfG3/bkrRwjf3MoqouqqqlVbUcOAf4TFX9EvBZ4OfbsDXATW15U1unbf9MVdUYW5akBW8+fc/ifcC7k2ylNydxdatfDbyi1d8NrJtQf5K0YE3iMtQ/qarPAZ9ry48AJ80x5u+BXxhrY5Kk7zKfziwkSfOUYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROYw+LJMuSfDbJA0nuT3Jhqx+dZHOSh9vPo1o9Sa5IsjXJPUlWjrtnSVroJnFmsQt4T1WdCJwMXJDkRGAdcEtVrQBuaesAZwAr2mstcOX4W5akhW3sYVFVT1TVXW35G8CDwBJgNbCxDdsInN2WVwPXVM+twJFJjhtv15K0sE10ziLJcuB1wG3AsVX1RNv0JHBsW14CbOt720yr7bmvtUm2JNkyOzs7uqYlaQGaWFgk+T7gY8C7qurZ/m1VVUDty/6qan1VTVfV9NTU1BA7lSRNJCySvJheUFxbVR9v5a/svrzUfu5o9e3Asr63L201SdKYTOJuqABXAw9W1Yf6Nm0C1rTlNcBNffV3tLuiTgae6btcJUkag8UTOOYpwNuBe5N8odUuBi4FbkhyPvAY8La27WbgLcBW4DngvLF2K0kaf1hU1f8BspfNq+YYX8AFI21KkvSC/Aa3JKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqdPiSTcwqCSnA5cDi4CrqurSCbc0dMvXfWLSLYzdo5eeOekWFoyF+O9rIRrV/6cOirBIsgj4feBNwAxwR5JNVfXAZDvTgfIXmHRwOFguQ50EbK2qR6pqJ3A9sHrCPUnSgnFQnFkAS4BtfeszwBv6ByRZC6xtq3+X5KEDON4xwFcP4P0HAz/jocHPeGgY2mfMBw7o7T+8tw0HS1h0qqr1wPph7CvJlqqaHsa+5is/46HBz3hoOBg+48FyGWo7sKxvfWmrSZLG4GAJizuAFUmOT/IS4Bxg04R7kqQF46C4DFVVu5K8E/gkvVtnN1TV/SM85FAuZ81zfsZDg5/x0DDvP2OqatI9SJLmuYPlMpQkaYIMC0lSJ8OiT5LTkzyUZGuSdZPuZ9iSLEvy2SQPJLk/yYWT7mlUkixKcneSv5h0L6OS5MgkNyb5YpIHk/zkpHsatiS/2f6t3pfkuiSHTbqnA5VkQ5IdSe7rqx2dZHOSh9vPoybZ41wMi6bvkSJnACcC5yY5cbJdDd0u4D1VdSJwMnDBIfgZd7sQeHDSTYzY5cBfVdWrgNdyiH3eJEuA3wCmq+rV9G5uOWeyXQ3FR4DT96itA26pqhXALW19XjEsnnfIP1Kkqp6oqrva8jfo/XJZMtmuhi/JUuBM4KpJ9zIqSY4Afhq4GqCqdlbV1yfa1GgsBl6WZDFwOPDlCfdzwKrq88BTe5RXAxvb8kbg7HH2NAjD4nlzPVLkkPtFuluS5cDrgNsm3MoofBh4L/CdCfcxSscDs8AftcttVyV5+aSbGqaq2g58EHgceAJ4pqo+NdmuRubYqnqiLT8JHDvJZuZiWCxASb4P+Bjwrqp6dtL9DFOStwI7qurOSfcyYouBlcCVVfU64JvMw0sXB6Jdt19NLxh/CHh5kl+ebFejV73vM8y77zQYFs9bEI8USfJiekFxbVV9fNL9jMApwFlJHqV3KfGNSf54si2NxAwwU1W7zwxvpBceh5KfAb5UVbNV9Q/Ax4F/OeGeRuUrSY4DaD93TLif72FYPO+Qf6RIktC7xv1gVX1o0v2MQlVdVFVLq2o5vf8NP1NVh9x/jVbVk8C2JCe00irgUPv7Lo8DJyc5vP3bXcUhNonfZxOwpi2vAW6aYC9zOige9zEOE3ikyCScArwduDfJF1rt4qq6eXIt6QD8OnBt+4+bR4DzJtzPUFXVbUluBO6idyff3RwEj8XokuQ64FTgmCQzwCXApcANSc4HHgPeNrkO5+bjPiRJnbwMJUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE7/H9acgWBnKk4mAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series([i.numpy() for i in predict_loss]).plot(kind='hist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.83      0.88      0.85       483\n",
      "         pos       0.94      0.92      0.93      1070\n",
      "\n",
      "    accuracy                           0.91      1553\n",
      "   macro avg       0.89      0.90      0.89      1553\n",
      "weighted avg       0.91      0.91      0.91      1553\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[423  60]\n",
      " [ 85 985]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAEYCAYAAAAtTS8wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhLklEQVR4nO3debxd873/8df7nEQSY2QQRCKuECIqiAhalNYt1Zp7qVkqpktLtahbQ7W3lBa9VH6mVoihhpprnvuTEERCULlIJEIkDUISkeRz/1jfw256ztk7sffZe5/1fnqsR9a01/rsc5KP7/e7vuv7VURgZpZHDdUOwMysWpwAzSy3nADNLLecAM0st5wAzSy3nADNLLecAHNEmT9KmiPpmS9xna9Jeq2csVWLpL6SPpbUWO1YrO3J/QDzQ9LXgBuAARHxSbXjqTRJbwE/iIiHqh2L1SaXAPNlXeCtPCS/UkjqUO0YrLqcAGuUpD6SbpP0vqTZki5J+xsk/ZekKZJmSholabV0rJ+kkHSopKmSZkk6PR0bDlwJbJOqfGdLOkzSU0vdNyT1T+u7SZokaa6k6ZJOTvt3lDSt4DMbS3pM0geSXpb03YJjf5J0qaR70nXGSlq/he/cFP/hkt5OVfWjJW0laUK6/iUF568v6ZH085klabSkrunYtUBf4K70fX9acP3hkqYCjxTs6yCpm6Rpkr6TrrGypMmSDvmyv0+rURHhpcYWoBF4EbgQWAnoDHw1HTsCmAz8G7AycBtwbTrWDwjgCqALsBnwKbBxOn4Y8FTBff5pO+0LoH9anwF8La2vDmyR1ncEpqX1jimenwErADsBc8mq2QB/AmYDQ4EOwGjgxha+d1P8I9N33gVYANwOrAH0BmYCO6Tz+wPfBDoBPYEngIsKrvcW8I1mrj8q/Vy7FOzrkM7ZBXg33e8K4JZq/33wUrnFJcDaNBRYG/hJRHwSEQsioqmkdiDwu4h4IyI+Bk4D9l+qOnd2RMyPiBfJEulmyxnHZ8BASatGxJyIeL6Zc4aRJeJzI2JhRDwC3A0cUHDOXyLimYhYRJYABxe57znpOz8AfALcEBEzI2I68CSwOUBETI6IByPi04h4H/gdsEMJ3+us9HOdv/SBdM+bgYeB3YCjSrie1SknwNrUB5iSEsbS1gamFGxPIStZ9SrY927B+jyyBLU89iFLAlMkPS5pmxbieTsiliwVU+8vEc97Bevzm9leGUBSL0k3pur5R8B1QI8i1wZ4u8jxy4FBwJ8iYnYJ17M65QRYm94G+rbQSP8O2cOMJn2BRfxzkijVJ8CKTRuS1iw8GBHPRsQeZNXB24E/txBPH0mFf5f6AtOXI55l9d9k1ddNI2JV4CBABcdb6uLQYteH1B3mcrJq8rFN7aHWPjkB1qZnyNrfzpW0kqTOkrZLx24ATpS0nqSVyZLATS2UFot5EdhE0mBJnYGzmg5IWkHSgZJWi4jPgI+AJc1cYyxZqe6nkjpK2hH4DnDjcsSzrFYBPgY+lNQb+MlSx98jaytdFj8jS5BHAOcDo9xHsP1yAqxBEbGYLIn0B6YC04D/SIevBq4la/B/k+whwfHLeZ+/A78AHgJeB55a6pSDgbdS9fJosvbHpa+xMMW6KzAL+ANwSES8ujwxLaOzgS2AD4F7yB4IFfo18F/p6fHJxS4maUvgJLL4FwPnkSXDU8satdUMd4Q2s9xyCdDMcssJ0MxyywnQzHLLCdDMcquuXwZfZfWVo3vv7tUOw1rQvbN/N7Xu+edemBURPct5TfXoHCxsrsfUUuZ+dn9EfKuc915WdZ0Au/fuzuk3n1LtMKwFB294WLVDsCK6dFhpSvGzltHCJTCsV/HzHpxWyls7FVXXCdDMapCom8Y1J0AzKz+p+Dk1wAnQzMpM0OAEaGZ55CqwmeWaq8Bmllv1kf+cAM2szITbAM0sx5wAzSy36iP/OQGaWZm5CmxmuVYf+c8J0MzKTILG+ugI6ARoZuXnEqCZ5ZY7QptZbtVH/nMCNLMy81NgM8s1J0Azy636eAjsBGhmZSb5IYiZ5Vh95D8nQDOrgMb6yIBOgGZWXsJVYDPLsfrIf06AZlYB7gZjZrnlKrCZ5ZKESigBRhuEUowToJmVnUooAToBmlm7VCc1YCdAMyuvbCyE4hlwceVDKcoJ0MzKS9DQUB8vAzsBmlmZqaQ2wFrgBGhmZVcn+c8J0MzKK3sTrj4yoBOgmZWXnADNLMca5IcgZpZTdVIAdAI0s/ISKqkfYC2oj3KqmdUVSUWXEq9zoqSXJb0k6QZJnSWtJ2mspMmSbpK0Qjq3U9qenI73K3Z9J0AzKy9BQ4OKLkUvI/UGTgCGRMQgoBHYHzgPuDAi+gNzgOHpI8OBOWn/hem8VjkBmllZNXWDKUcJkKyZroukDsCKwAxgJ+CWdPwaYM+0vkfaJh3fWUVu5ARoZmVXYgLsIWlcwTKi8BoRMR24AJhKlvg+BJ4DPoiIRem0aUDvtN4beDt9dlE6v3trcfohiJmVWcklvFkRMaTFq0irk5Xq1gM+AG4GvlWOCJs4AZpZeaU2wDL4BvBmRLwPIOk2YDugq6QOqZS3DjA9nT8d6ANMS1Xm1YDZrd3ACbCNLVm8hF/tdx5de3Xl+MuO4cqf/JEpL0+lsUMj/TZdl4PO+j4dOjYy/uEXueN/7kYSjR0a+d6p+7DBlv2rHX6ufPDBBxwz4jgmvTwJSYy84jI2HLABBx9wCFOmTGXddfty3Y3Xsvrqq1c71JpSxlfhpgLDJK0IzAd2BsYBjwL7AjcChwJ3pPPvTNtPp+OPRESr4666DbCNPXzto6y1/pqfb2+9+1b84p4zOPOO0/ns08946ta/AbDRsAGc8ZefccZffsahvzyIUWdcX62Qc+vkE3/CLv/+TV58+QWeeX4MG208gAvO+y077rQjL706gR132pELzvtttcOsSeV4CBIRY8keZjwPTCTLV5cDpwAnSZpM1sZ3VfrIVUD3tP8k4NRi93ACbENz3p3DxMdf4qv7bPv5vk13GPT5X4h+m/ZjzrsfANB5pc6f/yX5dP6nddOzvr348MMPeerJv3HYEYcCsMIKK9C1a1fuvuseDjrkQAAOOuRA7rrz7mqGWbMapKJLKSLizIjYKCIGRcTBEfFpRLwREUMjon9E7BcRn6ZzF6Tt/un4G8Wu7ypwG7rp3FvY5+S9WPDJgn85tuizxYy58xn2P23fz/e98NB4brvwTubOnsvxI49py1Bz760336JHjx6MGH4UEydMZPMtNueCC89n5nszWWuttQBYc801mfnezCpHWoNUP6/CuQTYRiY8NpFVuq3Cupv0bfb49efcyIZD+rPBkC/a+Tb/xmDOuecMjr1kBHf83iWNtrRo0WLGvzCeI486kjHjnmbFlVb8l+ruMvZny43sVbiGokstqI0ocmDy82/w4qMTOe0bP+eKH1/Nq2Nf46qf/gmAuy69h7n/+Jj9Ttm72c9uOGQDZk2bxdw5H7dhxPnWe5216b1Ob4ZuvRUAe+29F+NfGM8avdZgxowZAMyYMYOea/SsZpg1q4wdoSuqYglQUj9Jr0i6Ir3L94CkLpLWl3SfpOckPSlpo3T++pLGSJoo6ZeS2tW/9r1P2oPfPPorfv3QORz52yPYaOsBDP/NYTx5y994+W+vcOQFh//TPAozp8yk6QHWlElTWbRwESt3Xala4efOmmuuyTrrrMPfX/s7AI898hgbbbwR3959N64bNRqA60aNZvfvfLuaYdasekmAlW4D3AA4ICKOlPRnYB/gcODoiHhd0tbAH8hebbkYuDgibpB0dIXjqhmjz76Rbmt349wDLgBgi28OZvdjd+P5B8fz9B1jaezQyAqdV+DI3x5RM39p8uJ3F1/A4YccwcKFC+m33npcftVIlixZwkH7H8w1fxxF3759uO7Ga6sdZk2ql7+qKtJNZvkvnI3E8GBEbJC2TwE6AqcDrxWc2ikiNpY0G+gVEYskrQq8ExErN3PdEcAIgG5rddvy3IfPqUj89uUdvOFh1Q7BiujSYaXnWnsbY3l07rNa9PnRsKLnTT75gbLfe1lVugT4acH6YqAX2Xt8g5f3ghFxOVlfIPoNWrcWJpc3s6XUS22lrR+CfAS8KWk/AGU2S8fGkFWRIRvyxszqlFR8qQXVeAp8IDBc0ovAy2QvOwP8iKx39wSgP9lIDmZWh3L/ECQi3gIGFWxfUHC4uREdpgPDIiIk7Q8MqFRsZlY58qxwy2VL4JI0gOEHwBHVDcfMlleZRoOpuJpJgBHxJLBZ0RPNrMbVThW3mJpJgGbWfjgBmlkuuQ3QzHLNbYBmll8uAZpZPvkhiJnlVQ296VGME6CZlVUZJ0WqOCdAMyu7wrEta5kToJmVXZ0UAJ0AzazMamiwg2KcAM2srNwGaGa55jZAM8snd4MxszxzFdjMckl+E8TM8swJ0MzySR4NxszyzCVAM8srV4HNLJcE1EkN2AnQzMpMotEdoc0sj/wqnJnlWn2U/1pJgJL+B4iWjkfECRWJyMzqXkM7KAGOa7MozKzdEOVrA5TUFbgSGERWIDsCeA24CegHvAV8LyLmKKt3XwzsBswDDouI51u7fosJMCKuWSqQFSNi3vJ+ETPLifLOC3wxcF9E7CtpBWBF4GfAwxFxrqRTgVOBU4BdgQ3SsjVwWfqzRUXTtKRtJE0CXk3bm0n6w5f4QmbWjokssRRbil5HWg3YHrgKICIWRsQHwB5AUwHtGmDPtL4HMCoyY4CuktZq7R6lxHER8O/A7BTEiykoM7NmNUhFF6CHpHEFy4ilLrMe8D7wR0kvSLpS0kpAr4iYkc55F+iV1nsDbxd8flra16KSngJHxNtLFWkXl/I5M8unEqvAsyJiSCvHOwBbAMdHxFhJF5NVdz8XESGpxYe1xZRSAnxb0rZASOoo6WTgleW9oZm1bwIapaJLCaYB0yJibNq+hSwhvtdUtU1/zkzHpwN9Cj6/TtrXolIS4NHAcWRFyXeAwWnbzKwZxau/pXSTiYh3yQpgA9KunYFJwJ3AoWnfocAdaf1O4BBlhgEfFlSVm1W0ChwRs4ADi0ZrZkY2EEwZ+wEeD4xOT4DfAA4nK7j9WdJwYArwvXTuvWRdYCaTdYM5vNjFiyZASf9G9ih6GFk/nKeBEyPijWX+KmaWC+XqBhMR44Hm2gl3bubcYBlrp6VUga8H/gysBawN3AzcsCw3MbP8KGMbYMWVkgBXjIhrI2JRWq4DOlc6MDOrX+VoA2wLrb0L3C2t/jX1tr6RrAr8H2R1bTOzZtROgiumtTbA58gSXtM3OargWACnVSooM6tfKu+rcBXV2rvA67VlIGbWfrSHEuDnJA0CBlLQ9hcRoyoVlJnVr6aHIPWglG4wZwI7kiXAe8lGXHgKcAI0s2bVSwmwlKfA+5L1uXk3Ig4HNgNWq2hUZlbHhFR8qQWlVIHnR8QSSYskrUr23l2fYh8ys3xqGg6rHpSSAMelUVmvIHsy/DHZ2yBmZv9KtJ9Z4SLi2LQ6UtJ9wKoRMaGyYZlZvcrmBa6NKm4xrXWE3qK1Y8XG2m8L3Tp144D+B1U7DGtBl29tWO0QrEpqpY2vmNZKgL9t5VgAO5U5FjNrF0QDdZ4AI+LrbRmImbUf7aEEaGa2zCRoVDt5CGJmtqxcAjSzXFIdjQZTyrzAknSQpDPSdl9JQysfmpnVq+wxSOtLLSglij8A2wAHpO25wKUVi8jM6l5jQ0PRpRaUUgXeOiK2kPQCQETMSROUmJn9C6X/6kEpCfAzSY1kff+Q1BNYUtGozKx+lXdWuIoqpRz6e+AvwBqSfkU2FNZ/VzQqM6tr7WY0mIgYLek5siGxBOwZEa9UPDIzq0vZaDC10cZXTCkDovYlm2T4rsJ9ETG1koGZWb0SDTXykKOYUtoA7+GLyZE6A+sBrwGbVDAuM6tjdf8ucJOI2LRwO40Sc2wLp5tZzol2/CZIRDwvaetKBGNm7UAdPQUupQ3wpILNBmAL4J2KRWRmdU2IRjVWO4ySlFICXKVgfRFZm+CtlQnHzNqDdlEFTh2gV4mIk9soHjNrB+r+TRBJHSJikaTt2jIgM6t39TMaTGslwGfI2vvGS7oTuBn4pOlgRNxW4djMrA6J9jUgamdgNtkcIE39AQNwAjSzfyVQO0iAa6QnwC/xReJrEhWNyszqWPsYDaYRWBma/SZOgGbWrHYxLzAwIyJ+0WaRmFm7US/dYFqrqNfHNzCzmtL0EKTYUtK1pEZJL0i6O22vJ2mspMmSbmoanFlSp7Q9OR3vV8r1W4ti55IiNDP7J0JqKLqU6IdA4fB75wEXRkR/YA4wPO0fDsxJ+y9M5xXVYhQR8Y9SIzQzK1R8SqTiFUxJ6wDfBq5M2yLrjXJLOuUaYM+0vkfaJh3fWSXUw+vjWbWZ1Q2pbCNCXwT8lC+m4OgOfBARi9L2NKB3Wu8NvA2Qjn+Yzm+VE6CZlZloUEPRBeghaVzBMuLzK0i7AzMj4rlKRuqJ0c2s7EocEHVWRAxp4dh2wHcl7Ub2MsaqwMVA16bXdIF1gOnp/OlAH2CapA7AamQvcBSJ08ysjLIBUb/cQ5CIOC0i1omIfsD+wCMRcSDwKLBvOu1Q4I60fmfaJh1/JCKK9ld2AjSzMlNJ/y2nU4CTJE0ma+O7Ku2/Cuie9p8EnFrKxVwFNrOyK2dH6Ih4DHgsrb8BDG3mnAXAfst6bSdAMyu7hnYwGIKZ2TLL5gWujxfJnADNrLxK7+dXdU6AZlZ2qpPnq06AZlZW2XBYToBmlkvtY04QM7Pl0h5GhDYzWy5+CGJmuST8EMTMckvtalpMM7PSyVVgM8uprApcHwmwPsqp7dQlF1/KVpttzdDBwzj8oCNYsGABRw0/hkEbbsq2Q77KtkO+yoTxE6odZq6csNdwJl7+EC9d8TA/3CubbmKz9Qfy9O/v5IWR9/Pspfew1YDBAOzwlW344PZJvDDyfl4YeT8/P+hH1Qu8xpRpROiKcwmwSt6Z/g4jLx3Jsy8+Q5cuXTjkgEO55c+3AvDLX5/DnvvsWd0Ac2iTfgM4ctcDGHr87iz87DPu+/V13D32YX5z5Omcfe2F3Pfso+w6dCd+c+TpfP3kbOCRJyc+w3d+flh1A685olGN1Q6iJE6AVbRo0WLmz59Px44dmTd/PmuttWa1Q8q1jfv2Z+yr45n/6QIAHp8whr2/uisRwaorrgzAaiutwjuz36tmmDXPVWArau3ea3PCicczcP1B9O+7Iautuio7fzObifTsM85h2BbbcurJp/Hpp59WOdL8eOmt1/japkPptkpXunTqzG5Dd6JPz7X50WVncf6I/2Lq6Ge4YMTPOe2qX3/+mW0Gbsn4kQ9w76+uZeC6G1Yx+tpSL1VgJ8AqmTNnDvfcdQ8T/z6B16e8xiefzOPG0Tdx9i/P5PmXxvH404/yj3/M4cLzL6p2qLnx6tTJnHfTH3jg3Ou577+vY/z/vsziJYs5ZvdDOPGys+l74FBOvOwsrvrxBQA8P3ki6x64NYOP3oX/ueOP3H72VUXukBcVHRG6rJwAq+Sxhx9j3X7r0rNnDzp27Mh39/wOY8eMZc211kQSnTp14uBDD2TcuIpOimVLufq+Gxly3G7s8ON9mfPxh/x92hscusu+3PbUvQDc/MTdDE0PQebO+5hPFswD4K/PPELHxg50X3X1aoVeU1wCBCT1k/SqpNGSXpF0i6QVJe0s6QVJEyVdLalTOv9cSZMkTZB0QSVjq7Z1+vbh2bHjmDdvHhHBY48+zoCNBvDujHcBiAjuvvMeBg7cuMqR5kvPrtlUsn16rs3e2+3K9Y/czjuz32OHr2wDwE6bb8fr098EoNfqPT//3FYDBtPQ0MDsj+a0fdA1RoJGNRZdakFbPAQZAAyPiL9JuppswpKjgJ0j4u+SRgHHSLoW2AvYKCJCUtfmLpbmDh0B0KdvnzYIvzK2GjqEPffeg68O3Z4OHTqw2eCvcPgPDmPv7+zDrPdnExF8ZbNNuejSC6sdaq7cesbldF91dT5btIjjLjmdDz/5iCN/91MuPvZsOjR2YMHCTxlx0SkA7Lv9tzlm94NZtHgx8xcuYP9fHVvl6GtF7VRxi1EJM8ct/8WlfsATEdE3be8E/BxojIjt076dgeOA7wHPpeVu4O6IWNja9bfYcvN4YszjFYvfvpxVdhtY7RCsmIemP9fK3LzLZePBG8U1D15R9Lyt19i+7PdeVm3RBrh0hv2g2ZOyiY6HArcAuwP3VTYsM6sUPwT5Ql9J26T17wPjgH6S+qd9BwOPS1oZWC0i7gVOBDZrg9jMrMzKMTF6W2mLNsDXgONS+98k4ARgDHCzpA7As8BIoBtwh6TOZD/Dk9ogNjMru9op4RXTFglwUUQctNS+h4HNl9o3g2YmPDaz+lMr3VyK8atwZlZ2LgECEfEWMKiS9zCz2uJZ4cwsx9wGaGY55gRoZvnkIfHNLM9cAjSzXBLyQxAzyy+XAM0st9wGaGa55RKgmeWS2wDNLOfqowRYH2nazOqHyjMniKQ+kh5N02S8LOmHaX83SQ9Kej39uXraL0m/lzQ5TauxRbF7OAGaWdmVaUDURcCPI2IgMIxsWL2BwKnAwxGxAdnIUqem83cFNkjLCOCyYjdwAjSzsitHAoyIGRHxfFqfC7wC9Ab2AK5Jp10D7JnW9wBGRWYM0FXSWq3dw22AZlZWy/AQpIekcQXbl0fE5c1eM5tfaHNgLNArImakQ+8CvdJ6b+Dtgo9NS/tm0AInQDMruxKruLNKmRQpTZdxK/CjiPiosP0wzSC53DO7uQpsZmVXronRJXUkS36jI+K2tPu9pqpt+nNm2j8dKJwrd520r0VOgGZWduVoA1SWJa8CXomI3xUcuhM4NK0fCtxRsP+Q9DR4GPBhQVW5Wa4Cm1lZlbEj9HZks0ZOlDQ+7fsZcC7wZ0nDgSlkc4oD3AvsBkwG5gGHF7uBE6CZVcCX7wgdEU+1cqGdmzk/gOOW5R5OgGZWdvXxHogToJlVgEeDMbMccwI0s1zyrHBmllOqo0mR3A/QzHLLJUAzKztXgc0st5wAzSy33AZoZlbjXAI0szJzNxgzyzUnQDPLIQENddIG6ARoZhXgBGhmOVUf6c8J0Mwqoj5SoBOgmZVZ6XN+VJsToJmVlfCbIGaWa06AZpZT9ZH+nADNrOyEyjMrXMU5AZpZ2bkEaGY5Vh8p0AnQzMrLQ+KbmdU+ZZOp1ydJ7wNTqh1HGfUAZlU7CGtVe/sdrRsRPct5QUn3kf2cipkVEd8q572XVV0nwPZG0riIGFLtOKxl/h21L64Cm1luOQGaWW45AdaWy6sdgBXl31E74jZAM8stlwDNLLecAM0st5wAzSy3nADNLLecAGuU0suUqpeXKnPKv5/65gRYuzYEiIjwP7LaI2kTSb3C3SjqmhNgDZK0AfCspEvASbDWSPoucBnQr2Cffz91yP0Aa0z6x3Ug8CZwMHBXRBydjskljuqStAlwA7B3REyW1ANYMSKmSmqIiCVVDtGWgUuANUTSSsBJwPURcSowCPi6pN+DS4LVVPBz7wXMBNaQdAZwDTBB0mAnv/rjBFhb5pGV/KYBRMQc4IfA4ZLOSftcAqyO7unPx4BxwMXAG8D+wG+ATaoTln0ZToA1QNIASX2AlYBngNGSVkyHPyZ7/3QXSdtXK8Y8k/Qt4HpJo4CzgHMjYquIuI4s8R1C9j8uqzMeEr/KJO0KnAfcAhxAVu3dBHhS0sPA94HvAovTYm0otfldAhwOrApsCYyUdDJZqfAa4McR8f+rF6UtL5cAq0hSf+BMYC9gMrCErEH9P4GfAE8AO5GVDHcBZlQp1DzrBDwYEU8CfwWuBuYCA4CJwF4RcbfbZuuTS4DVNQcYTVaq+BGwR0TMlbQLMCYiPkolkPOBQyPijeqFmi+StgPWAzoC+0m6KyLuBaZJWkQ2lPwSYBK4bbZeOQFWgaQdgI3JGtFPJPs9rB8Rn0kaBpwKHAl8RPZA5NsRMbta8eaNpG2BK4HngPeAqcAZqZ32ZWBbYFT1IrRycT/ANiZpa7Jq1GvAK0AXskb0XwGLgCOAsyLijqoFmWOShpK1yZ4WEWMk/RtZG+y2QDeySbjuiojbqxellYtLgG0o/eM6GzggIiZIOhhYF7iJ7MHHS8BPI+JBd3qumtWA7cnaXscAb5OV1NcB9m/q6+ffT/vghyBtqyvwDeCbafsGsn9cc4GJEXFRRDwIblOqlvTz3xs4QtIBEfEZ8CGwA9Cj6WGHfz/tg0uAbSgiHpC0N/BrSe9ExA2SbkqHX6xmbPaFiLhD0hKy/pj7kD2dPyciZlY5NCsztwFWgaTdgHOA30fENdWOx5qX3sv+BTA6Is536a/9cQmwCiLiXkkdgHMlPQi86/dIa09E3ClpAXC1pP+NiNuqHZOVl0uAVSSpZ0S8X+04rHWSvgn8r/thtj9OgGaWW34KbGa55QRoZrnlBGhmueUEaGa55QTYjkhaLGm8pJck3VwwqOryXOtPkvZN61dKGtjKuTumAQSW9R5vpTk1Stq/1DkfL+O9zkpj+Jl9zgmwfZkfEYMjYhCwEDi68GDqe7jMIuIHETGplVN2JBsswKyuOAG2X08C/VPp7ElJdwKTJDVKOl/Ss5ImSDoKspf7JV0i6TVJDwFrNF1I0mOShqT1b0l6XtKLkh6W1I8s0Z6YSp9fk9RT0q3pHs+msfWQ1F3SA5JelnQlUHQQUUm3S3oufWbEUscuTPsfltQz7Vtf0n3pM09K2qgsP01rl/wmSDuUSnq7AvelXVsAgyLizZREPoyIrSR1Av4m6QFgc7JRjgeSzXw2iWzYrsLr9gSuALZP1+oWEf+QNBL4OCIuSOddD1wYEU9J6gvcTzb+4ZnAUxHxC0nfBoaX8HWOSPfoQjZX8q1pbMSVgHERcaKy2dnOBP6TbP6UoyPi9TT02B/IRnYx+xdOgO1LF0nj0/qTwFVkVdNnIqJp0p5dgK80te+RDf+0AdkQUDdExGLgHUmPNHP9YcATTdeKiH+0EMc3gIEFo8SvKmnldI+902fvkTSnhO90gqS90nqfFOtssgEKmgaSuA64Ld1jW+Dmgnt3KuEellNOgO3L/IgYXLgjJYJPCncBx0fE/Uudt1sZ42gAhkXEgmZiKZmkHcmS6TYRMU/SY0DnFk6PdN8Plv4ZmLXEbYD5cz9wjKSOAJI2VDYh+xPAf6Q2wrWArzfz2THA9pLWS5/tlvbPBVYpOO8B4PimDUmD0+oTZLPcNc2Gt3qRWFcD5qTktxFZCbRJA9BUiv0+WdX6I+BNSfule0jSZkXuYTnmBJg/V5K17z0v6SXg/5HVBP4CvJ6OjQKeXvqDaeCGEWTVzRf5ogp6F7BX00MQ4ARgSHrIMokvnkafTZZAXyarCk8tEut9QAdJrwDnkiXgJp8AQ9N32Ils2CqAA4HhKb6XgT1K+JlYTnkwBDPLLZcAzSy3nADNLLecAM0st5wAzSy3nADNLLecAM0st5wAzSy3/g/TthHx7UXE7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_true = test.label\n",
    "print(classification_report(y_true, y_pred_li, target_names=['neg', 'pos']))\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred_li)\n",
    "plot_confusion_matrix(cnf_matrix, classes=['neg', 'pos'],normalize=False,\n",
    "                    title='confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back translate roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....model is loading\n",
      "You got it\n",
      "CPU times: user 1min 54s, sys: 929 ms, total: 1min 55s\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "translate_roberta =  RoBertaFineTune(False).load_model('./roberta/back_translate_roberta_checkpoint_v3', latest=True)\n",
    "y_translate_pred_li, y_translate_pred_logitis_li, pooler_translate_out_li, predict_translate_loss = predict(translate_roberta, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series([i.numpy() for i in predict_translate_loss]).plot(kind='hist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.85      0.88      0.86       483\n",
      "         pos       0.94      0.93      0.94      1070\n",
      "\n",
      "    accuracy                           0.91      1553\n",
      "   macro avg       0.89      0.90      0.90      1553\n",
      "weighted avg       0.91      0.91      0.91      1553\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[423  60]\n",
      " [ 77 993]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_true = test.label\n",
    "print(classification_report(y_true, y_translate_pred_li, target_names=['neg', 'pos']))\n",
    "cnf_matrix = confusion_matrix(y_true, y_translate_pred_li)\n",
    "plot_confusion_matrix(cnf_matrix, classes=['neg', 'pos'],normalize=False,\n",
    "                    title='confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
